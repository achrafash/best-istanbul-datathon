{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "n-beats.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMuSm25xHIEUCtE5/3DQFc4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AchrafAsh/best-istanbul-datathon/blob/main/n_beats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbJrbWtp7ARX"
      },
      "source": [
        "import pickle\n",
        "import random\n",
        "from time import time\n",
        "from typing import Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.functional import mse_loss, l1_loss, binary_cross_entropy, cross_entropy\n",
        "from torch.optim import Optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prBbaYwc66wv"
      },
      "source": [
        "class NBeatsNet(nn.Module):\n",
        "    SEASONALITY_BLOCK = 'seasonality'\n",
        "    TREND_BLOCK = 'trend'\n",
        "    GENERIC_BLOCK = 'generic'\n",
        "\n",
        "    def __init__(self,\n",
        "                 device=torch.device('cpu'),\n",
        "                 stack_types=(TREND_BLOCK, SEASONALITY_BLOCK),\n",
        "                 nb_blocks_per_stack=3,\n",
        "                 forecast_length=5,\n",
        "                 backcast_length=10,\n",
        "                 thetas_dim=(4, 8),\n",
        "                 share_weights_in_stack=False,\n",
        "                 hidden_layer_units=256,\n",
        "                 nb_harmonics=None):\n",
        "        super(NBeatsNet, self).__init__()\n",
        "        self.forecast_length = forecast_length\n",
        "        self.backcast_length = backcast_length\n",
        "        self.hidden_layer_units = hidden_layer_units\n",
        "        self.nb_blocks_per_stack = nb_blocks_per_stack\n",
        "        self.share_weights_in_stack = share_weights_in_stack\n",
        "        self.nb_harmonics = nb_harmonics\n",
        "        self.stack_types = stack_types\n",
        "        self.stacks = []\n",
        "        self.thetas_dim = thetas_dim\n",
        "        self.parameters = []\n",
        "        self.device = device\n",
        "        print('| N-Beats')\n",
        "        for stack_id in range(len(self.stack_types)):\n",
        "            self.stacks.append(self.create_stack(stack_id))\n",
        "        self.parameters = nn.ParameterList(self.parameters)\n",
        "        self.to(self.device)\n",
        "        self._loss = None\n",
        "        self._opt = None\n",
        "\n",
        "    def create_stack(self, stack_id):\n",
        "        stack_type = self.stack_types[stack_id]\n",
        "        print(f'| --  Stack {stack_type.title()} (#{stack_id}) (share_weights_in_stack={self.share_weights_in_stack})')\n",
        "        blocks = []\n",
        "        for block_id in range(self.nb_blocks_per_stack):\n",
        "            block_init = NBeatsNet.select_block(stack_type)\n",
        "            if self.share_weights_in_stack and block_id != 0:\n",
        "                block = blocks[-1]  # pick up the last one when we share weights.\n",
        "            else:\n",
        "                block = block_init(self.hidden_layer_units, self.thetas_dim[stack_id],\n",
        "                                   self.device, self.backcast_length, self.forecast_length, self.nb_harmonics)\n",
        "                self.parameters.extend(block.parameters())\n",
        "            print(f'     | -- {block}')\n",
        "            blocks.append(block)\n",
        "        return blocks\n",
        "\n",
        "    def save(self, filename: str):\n",
        "        torch.save(self, filename)\n",
        "\n",
        "    @staticmethod\n",
        "    def load(f, map_location=None, pickle_module=pickle, **pickle_load_args):\n",
        "        return torch.load(f, map_location, pickle_module, **pickle_load_args)\n",
        "\n",
        "    @staticmethod\n",
        "    def select_block(block_type):\n",
        "        if block_type == NBeatsNet.SEASONALITY_BLOCK:\n",
        "            return SeasonalityBlock\n",
        "        elif block_type == NBeatsNet.TREND_BLOCK:\n",
        "            return TrendBlock\n",
        "        else:\n",
        "            return GenericBlock\n",
        "\n",
        "    def compile(self, loss: str, optimizer: Union[str, Optimizer]):\n",
        "        if loss == 'mae':\n",
        "            loss_ = l1_loss\n",
        "        elif loss == 'mse':\n",
        "            loss_ = mse_loss\n",
        "        elif loss == 'cross_entropy':\n",
        "            loss_ = cross_entropy\n",
        "        elif loss == 'binary_crossentropy':\n",
        "            loss_ = binary_cross_entropy\n",
        "        else:\n",
        "            raise ValueError(f'Unknown loss name: {loss}.')\n",
        "        # noinspection PyArgumentList\n",
        "        if isinstance(optimizer, str):\n",
        "            if optimizer == 'adam':\n",
        "                opt_ = optim.Adam\n",
        "            elif optimizer == 'sgd':\n",
        "                opt_ = optim.SGD\n",
        "            elif optimizer == 'rmsprop':\n",
        "                opt_ = optim.RMSprop\n",
        "            else:\n",
        "                raise ValueError(f'Unknown opt name: {optimizer}.')\n",
        "            opt_ = opt_(lr=1e-4, params=self.parameters())\n",
        "        else:\n",
        "            opt_ = optimizer\n",
        "        self._opt = opt_\n",
        "        self._loss = loss_\n",
        "\n",
        "\n",
        "    def fit(self, x_train, y_train, validation_data=None, epochs=10, batch_size=32):\n",
        "\n",
        "        def split(arr, size):\n",
        "            arrays = []\n",
        "            while len(arr) > size:\n",
        "                slice_ = arr[:size]\n",
        "                arrays.append(slice_)\n",
        "                arr = arr[size:]\n",
        "            arrays.append(arr)\n",
        "            return arrays\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            x_train_list = split(x_train, batch_size)\n",
        "            y_train_list = split(y_train, batch_size)\n",
        "            assert len(x_train_list) == len(y_train_list)\n",
        "            shuffled_indices = list(range(len(x_train_list)))\n",
        "            random.shuffle(shuffled_indices)\n",
        "            self.train()\n",
        "            train_loss = []\n",
        "            timer = time()\n",
        "            for batch_id in shuffled_indices:\n",
        "                batch_x, batch_y = x_train_list[batch_id], y_train_list[batch_id]\n",
        "                self._opt.zero_grad()\n",
        "                _, forecast = self(torch.tensor(batch_x, dtype=torch.float).to(self.device))\n",
        "                loss = self._loss(forecast, squeeze_last_dim(torch.tensor(batch_y, dtype=torch.float).to(self.device)))\n",
        "                train_loss.append(loss.item())\n",
        "                loss.backward()\n",
        "                self._opt.step()\n",
        "            elapsed_time = time() - timer\n",
        "            train_loss = np.mean(train_loss)\n",
        "\n",
        "            test_loss = '[undefined]'\n",
        "            if validation_data is not None:\n",
        "                x_test, y_test = validation_data\n",
        "                self.eval()\n",
        "                _, forecast = self(torch.tensor(x_test, dtype=torch.float).to(self.device))\n",
        "                test_loss = self._loss(forecast, squeeze_last_dim(torch.tensor(y_test, dtype=torch.float))).item()\n",
        "\n",
        "            num_samples = len(x_train_list)\n",
        "            time_per_step = int(elapsed_time / num_samples * 1000)\n",
        "            print(f'Epoch {str(epoch + 1).zfill(len(str(epochs)))}/{epochs}')\n",
        "            print(f'{num_samples}/{num_samples} [==============================] - '\n",
        "                  f'{int(elapsed_time)}s {time_per_step}ms/step - '\n",
        "                  f'loss: {train_loss:.4f} - val_loss: {test_loss:.4f}')\n",
        "\n",
        "\n",
        "    def predict(self, x, return_backcast=False):\n",
        "        self.eval()\n",
        "        b, f = self(torch.tensor(x, dtype=torch.float).to(self.device))\n",
        "        b, f = b.detach().numpy(), f.detach().numpy()\n",
        "        if len(x.shape) == 3:\n",
        "            b = np.expand_dims(b, axis=-1)\n",
        "            f = np.expand_dims(f, axis=-1)\n",
        "        if return_backcast:\n",
        "            return b\n",
        "        return f\n",
        "\n",
        "    def forward(self, backcast):\n",
        "        backcast = squeeze_last_dim(backcast)\n",
        "        forecast = torch.zeros(size=(backcast.size()[0], self.forecast_length,))  # maybe batch size here.\n",
        "        for stack_id in range(len(self.stacks)):\n",
        "            for block_id in range(len(self.stacks[stack_id])):\n",
        "                b, f = self.stacks[stack_id][block_id](backcast)\n",
        "                backcast = backcast.to(self.device) - b\n",
        "                forecast = forecast.to(self.device) + f\n",
        "        return backcast, forecast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOqI-8m17GTW"
      },
      "source": [
        "def squeeze_last_dim(tensor):\n",
        "    if len(tensor.shape) == 3 and tensor.shape[-1] == 1:  # (128, 10, 1) => (128, 10).\n",
        "        return tensor[..., 0]\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def seasonality_model(thetas, t, device):\n",
        "    p = thetas.size()[-1]\n",
        "    assert p <= thetas.shape[1], 'thetas_dim is too big.'\n",
        "    p1, p2 = (p // 2, p // 2) if p % 2 == 0 else (p // 2, p // 2 + 1)\n",
        "    s1 = torch.tensor([np.cos(2 * np.pi * i * t) for i in range(p1)]).float()  # H/2-1\n",
        "    s2 = torch.tensor([np.sin(2 * np.pi * i * t) for i in range(p2)]).float()\n",
        "    S = torch.cat([s1, s2])\n",
        "    return thetas.mm(S.to(device))\n",
        "\n",
        "\n",
        "def trend_model(thetas, t, device):\n",
        "    p = thetas.size()[-1]\n",
        "    assert p <= 4, 'thetas_dim is too big.'\n",
        "    T = torch.tensor([t ** i for i in range(p)]).float()\n",
        "    return thetas.mm(T.to(device))\n",
        "\n",
        "\n",
        "def linear_space(backcast_length, forecast_length):\n",
        "    ls = np.arange(-backcast_length, forecast_length, 1) / forecast_length\n",
        "    b_ls = ls[:backcast_length]\n",
        "    f_ls = ls[backcast_length:]\n",
        "    return b_ls, f_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp8IgVRy7QJi"
      },
      "source": [
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, units, thetas_dim, device, backcast_length=10, forecast_length=5, share_thetas=False,\n",
        "                 nb_harmonics=None):\n",
        "        super(Block, self).__init__()\n",
        "        self.units = units\n",
        "        self.thetas_dim = thetas_dim\n",
        "        self.backcast_length = backcast_length\n",
        "        self.forecast_length = forecast_length\n",
        "        self.share_thetas = share_thetas\n",
        "        self.fc1 = nn.Linear(backcast_length, units)\n",
        "        self.fc2 = nn.Linear(units, units)\n",
        "        self.fc3 = nn.Linear(units, units)\n",
        "        self.fc4 = nn.Linear(units, units)\n",
        "        self.device = device\n",
        "        self.backcast_linspace, self.forecast_linspace = linear_space(backcast_length, forecast_length)\n",
        "        if share_thetas:\n",
        "            self.theta_f_fc = self.theta_b_fc = nn.Linear(units, thetas_dim, bias=False)\n",
        "        else:\n",
        "            self.theta_b_fc = nn.Linear(units, thetas_dim, bias=False)\n",
        "            self.theta_f_fc = nn.Linear(units, thetas_dim, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = squeeze_last_dim(x)\n",
        "        x = F.relu(self.fc1(x.to(self.device)))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "    def __str__(self):\n",
        "        block_type = type(self).__name__\n",
        "        return f'{block_type}(units={self.units}, thetas_dim={self.thetas_dim}, ' \\\n",
        "               f'backcast_length={self.backcast_length}, forecast_length={self.forecast_length}, ' \\\n",
        "               f'share_thetas={self.share_thetas}) at @{id(self)}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeXjI4rH7OJn"
      },
      "source": [
        "class SeasonalityBlock(Block):\n",
        "\n",
        "    def __init__(self, units, thetas_dim, device, backcast_length=10, forecast_length=5, nb_harmonics=None):\n",
        "        if nb_harmonics:\n",
        "            super(SeasonalityBlock, self).__init__(units, nb_harmonics, device, backcast_length,\n",
        "                                                   forecast_length, share_thetas=True)\n",
        "        else:\n",
        "            super(SeasonalityBlock, self).__init__(units, forecast_length, device, backcast_length,\n",
        "                                                   forecast_length, share_thetas=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = super(SeasonalityBlock, self).forward(x)\n",
        "        backcast = seasonality_model(self.theta_b_fc(x), self.backcast_linspace, self.device)\n",
        "        forecast = seasonality_model(self.theta_f_fc(x), self.forecast_linspace, self.device)\n",
        "        return backcast, forecast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blz12Bzv7KMS"
      },
      "source": [
        "class TrendBlock(Block):\n",
        "\n",
        "    def __init__(self, units, thetas_dim, device, backcast_length=10, forecast_length=5, nb_harmonics=None):\n",
        "        super(TrendBlock, self).__init__(units, thetas_dim, device, backcast_length,\n",
        "                                         forecast_length, share_thetas=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = super(TrendBlock, self).forward(x)\n",
        "        backcast = trend_model(self.theta_b_fc(x), self.backcast_linspace, self.device)\n",
        "        forecast = trend_model(self.theta_f_fc(x), self.forecast_linspace, self.device)\n",
        "        return backcast, forecast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAdJz_BX7H6f"
      },
      "source": [
        "class GenericBlock(Block):\n",
        "\n",
        "    def __init__(self, units, thetas_dim, device, backcast_length=10, forecast_length=5, nb_harmonics=None):\n",
        "        super(GenericBlock, self).__init__(units, thetas_dim, device, backcast_length, forecast_length)\n",
        "\n",
        "        self.backcast_fc = nn.Linear(thetas_dim, backcast_length)\n",
        "        self.forecast_fc = nn.Linear(thetas_dim, forecast_length)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # no constraint for generic arch.\n",
        "        x = super(GenericBlock, self).forward(x)\n",
        "\n",
        "        theta_b = F.relu(self.theta_b_fc(x))\n",
        "        theta_f = F.relu(self.theta_f_fc(x))\n",
        "\n",
        "        backcast = self.backcast_fc(theta_b)  # generic. 3.3.\n",
        "        forecast = self.forecast_fc(theta_f)  # generic. 3.3.\n",
        "\n",
        "        return backcast, forecast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qCMvbU49b4T"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqYnYyNK9c7i"
      },
      "source": [
        "def split(arr, size):\n",
        "    arrays = []\n",
        "    while len(arr) > size:\n",
        "        slice_ = arr[:size]\n",
        "        arrays.append(slice_)\n",
        "        arr = arr[size:]\n",
        "    arrays.append(arr)\n",
        "    return arrays\n",
        "\n",
        "\n",
        "def batcher(dataset, batch_size, infinite=False):\n",
        "    while True:\n",
        "        x, y = dataset\n",
        "        for x_, y_ in zip(split(x, batch_size), split(y, batch_size)):\n",
        "            yield x_, y_\n",
        "        if not infinite:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XZtH0Gf9rvq"
      },
      "source": [
        "def simple_fit(net, optimiser, data_generator, on_save_callback=None, device=torch.device('cpu'), max_grad_steps=10000):\n",
        "    print('--- Training ---')\n",
        "    initial_grad_step = load(net, optimiser)\n",
        "    for grad_step, (x, target) in enumerate(data_generator):\n",
        "        grad_step += initial_grad_step\n",
        "        optimiser.zero_grad()\n",
        "        net.train()\n",
        "        backcast, forecast = net(torch.tensor(x, dtype=torch.float).to(device))\n",
        "        loss = F.mse_loss(forecast, torch.tensor(target, dtype=torch.float).to(device))\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "        print(f'grad_step = {str(grad_step).zfill(6)}, loss = {loss.item():.6f}')\n",
        "        if grad_step % 1000 == 0 or (grad_step < 1000 and grad_step % 100 == 0):\n",
        "            with torch.no_grad():\n",
        "                save(net, optimiser, grad_step)\n",
        "                if on_save_callback is not None:\n",
        "                    on_save_callback(x, target, grad_step)\n",
        "        if grad_step > max_grad_steps:\n",
        "            print('Finished.')\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59RoaYhU9qir"
      },
      "source": [
        "def run():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    forecast_length = 10\n",
        "    backcast_length = 5 * forecast_length\n",
        "    batch_size = 4  # greater than 4 for viz\n",
        "\n",
        "    data_gen = batcher(\n",
        "        # series\n",
        "        batch_size=batch_size,\n",
        "        infinite=True\n",
        "    )\n",
        "\n",
        "    print('--- Model ---')\n",
        "    net = NBeatsNet(device=device,\n",
        "                    stack_types=[NBeatsNet.TREND_BLOCK, NBeatsNet.SEASONALITY_BLOCK, NBeatsNet.GENERIC_BLOCK],\n",
        "                    forecast_length=forecast_length,\n",
        "                    thetas_dim=[2, 8, 3],\n",
        "                    nb_blocks_per_stack=3,\n",
        "                    backcast_length=backcast_length,\n",
        "                    hidden_layer_units=1024,\n",
        "                    share_weights_in_stack=False,\n",
        "                    nb_harmonics=None)\n",
        "\n",
        "    optimiser = optim.Adam(net.parameters())\n",
        "\n",
        "    def plot_model(x, target, grad_step):\n",
        "        if not args.disable_plot:\n",
        "            print('plot()')\n",
        "            plot(net, x, target, backcast_length, forecast_length, grad_step)\n",
        "\n",
        "    max_grad_steps = 10000\n",
        "    if args.test:\n",
        "        max_grad_steps = 5\n",
        "\n",
        "    simple_fit(net, optimiser, data_gen, None, device, max_grad_steps)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}